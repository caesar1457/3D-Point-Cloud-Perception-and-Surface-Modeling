# -*- coding: utf-8 -*-
"""Caesar_Zhao_Assignment2.2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12_69sHBj45NcY9XFJ11y9VSlQW0py-ql

# Past Sections from Assignment 1

In Assignment 2, we build upon the previous assignment and perform tasks related to regression problems.

---

First, we reload the dependencies from the previous assignment:
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install -q plotly
import plotly.express as px
import plotly.graph_objects as go

def plot_cloud(data=None, x='x', y='y', z='z', color=None, *, max_points=10_000, **kwargs):

    if max_points is not None and data is not None and len(data) > max_points:
        import sys
        print(f"Warning: too many points, trying to show only {max_points:,} points.", file=sys.stderr)
        skip = len(data) // max_points
        data = data[::skip]

    if isinstance(data, np.ndarray):
        m = data.shape[-1]
        if m == 3:
            x, y, z = data.T
        elif m == 4:
            x, y, z, color = data.T
        data_frame = None
    elif isinstance(data, pd.DataFrame):
        data_frame = data
    else:
        data_frame = None

    if (data_frame is not None
        and isinstance(color, str)
        and len(color) == 3
        and color not in data_frame.columns
        and all(c in data_frame.columns for c in color)
    ):
        update_color = data_frame[list(color)].to_numpy()
        color = None
    else:
        update_color = None

    fig = px.scatter_3d(
        data_frame,
        x=x, y=y, z=z,
        color=color,
        template=plot_cloud.template,
        **kwargs,
    )
    if update_color is not None:
        # has to be updated later because px.scatter_3d doesn't accept a matrix
        fig.data[0].marker.color = update_color

    return fig

plot_cloud.template = dict(
    layout=dict(
        margin=dict(
            # l=0, r=0,  # set left and right margin
            b=0, t=0,  # set bottom and top margin
        ),
        scene=dict(
            # xaxis_visible=False,  # hide axes
            # yaxis_visible=False,
            # zaxis_visible=False,
            aspectmode='data',  # set aspect ratio
        ),
    ),
    data=dict(
        scatter3d=[
            go.Scatter3d(
                marker_size=1,  # set default marker size
            ),
        ],
    ),
)

import math
import numpy as np
import pandas as pd

n_clusters = 1000

"""We now use the `request` package to download `df_test` that contains the data required for the rest of the assignment. `df_test` might be slightly different from the one you got in Assignment 1 depending on the features you used for the classification (it does not mean that the result you got in Assignment 1 is wrong)."""

import requests

# Shareable link
shareable_link = 'https://drive.google.com/file/d/1-5gZVjT5nIt4oAvTTVLk1zAmg9z55Nb1/view?usp=sharing'

# Extract file ID and create direct download URL
file_id = shareable_link.split('/')[-2]
url = f'https://drive.google.com/uc?export=download&id={file_id}'
print(f"Download URL: {url}")

# Download the file
output = 'df_test.pkl'
response = requests.get(url)
if response.status_code == 200:
    with open(output, 'wb') as f:
        f.write(response.content)
    print(f"File downloaded as '{output}'")
else:
    print(f"Failed to download. Status code: {response.status_code}")

# Load the DataFrame (for pickle files)
df_test = pd.read_pickle(output)

# Show the first few rows
df_test.head()

"""# Assignment 2

Assignment 2 will continue on from Assignment 1, using the clustered and classified point cloud. We will use linear and non-linear regression models to resample the point cloud (the marking criteria is provided in brackets):

1. Apply linear regression to buildings (30%)
2. Answer the questions related to the linear regression (20%)
3. Apply the GP for ground estimation (30%)
4. Answer the questions related to the GP section (20%)

---


You are required to:
 - Model each cluster classified as *building* with a *linear regression* model.
 - Model every point classified as *terrain* with a *Gaussian process* model.

 > Begin by inserting Assignment 1 here. Note: by shift-clicking and then right-clicking, you can select multiple notebook cells, copy, and paste them across notebooks.

 > In the subsequent tasks, use the test data set `df_test` and group the points into **100 clusters**. Do not use the ground truth class `labels`, only the predicted values `pred`.

# 1. Linear Regression

As we are working in 3 dimensions, we are going to use 2 dimensions to estimate the 3rd. As such, There are 3 possible choices for the estimated variable: $x$, $y$, or $z$. Luckily, it is easy to know which model to select: the one with the lowest *mean squared error*.

> Define a function to perform linear regression in each of the 3 dimensions, and select the model with the best error.

> Apply this process to each cluster, replacing the points with a linear approximation.

> The model can be used at arbitrary locations, use `bounding_grid` to query each model on a regular grid instead of at the original (training) locations.
"""

df_walls = df_test[df_test['pred'] == 'buildings']
positions = df_walls[['x','y','z']].to_numpy()
assignment = df_walls['cluster'].to_numpy()
print(positions)
print(f"positions[5]", positions[5])
df_walls

def bounding_grid(x, n=None):
    """
    Replaces a set of points by a similar number of points on a regular grid
    spanning the bounds of the original point set.

    x: numpy array, shape [n, d], n points in d dimensions.
    n: int (optional), minimum number of points to generate.
    """
    d = x.shape[-1]
    if n is None:
        n = len(x)
    mins = x.min(axis=0)
    maxs = x.max(axis=0)
    rngs = (maxs - mins)
    nums = np.ceil(rngs * np.power(n/rngs.prod(), 1/d)).astype(int)
    axes = [np.linspace(mn, mx, ns) for mn, mx, ns in zip(mins, maxs, nums)]
    grid = np.stack(np.meshgrid(*axes, indexing='ij'), axis=-1)
    return grid.reshape(nums.prod(), d)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

def lin_reg(points):
 ##..............TODO................
    best_dim = None
    best_model = None
    best_mse = np.inf

    # Iterate through x, y, z as target variables, select the optimal regression direction
    for dim in range(3):
        X = np.delete(points, dim, axis=1)  # Use the other two dimensions as input
        y = points[:, dim]  # Target variable

        model = LinearRegression()
        model.fit(X, y)
        y_pred = model.predict(X)
        mse = mean_squared_error(y, y_pred)

        if mse < best_mse:  # Select the regression direction with the lowest error
            best_mse = mse
            best_model = model
            best_dim = dim

    # Generate regular grid points (bounding_grid)
    grid_points = bounding_grid(points)  # Generate regular query points within the entire point cloud region
    grid_X = np.delete(grid_points, best_dim, axis=1)  # Use 2D data of regular points as input
    grid_y = best_model.predict(grid_X)  # Calculate fitted values

    # Combine new x, y, z coordinates
    fitted_points = np.insert(grid_X, best_dim, grid_y, axis=1)

    return fitted_points  # Return the regularized 3D point cloud

# Process all clusters
positions_lin = []
for i in range(n_clusters):
  ##TODO
    points = df_walls[df_walls['cluster'] == i][['x', 'y', 'z']].to_numpy()
    if len(points) == 0:
        continue

    points_lin = lin_reg(points)  # Calculate fitted points
    positions_lin.append(points_lin)

# Merge fitted point clouds of all clusters
positions_lin = np.concatenate(positions_lin)

plot_cloud(positions).show()
plot_cloud(positions_lin).show()

"""### Evaluation of Linear Regression per Cluster

To assess the linearity of each cluster of wall points, we perform linear regression in all three coordinate dimensions (x, y, z), selecting the dimension with the lowest mean squared error (MSE) as the regression target for each cluster.

The following bar charts show:

- **Mean Squared Error (MSE)** per cluster: lower MSE indicates better linear fit.
- **R² Score** per cluster: values closer to 1 indicate higher explained variance and better model performance.

These visualizations help evaluate how well each wall segment can be approximated using a linear model.

"""

import matplotlib.pyplot as plt

from sklearn.metrics import mean_squared_error, r2_score

# Collect evaluation metrics
cluster_ids = []
mse_list = []
r2_list = []
best_dims = []

for i in range(n_clusters):
    points = df_walls[df_walls['cluster'] == i][['x', 'y', 'z']].to_numpy()
    if len(points) == 0:
        continue

    best_mse = np.inf
    best_r2 = -np.inf
    best_dim = None

    for dim in range(3):
        X = np.delete(points, dim, axis=1)
        y = points[:, dim]
        model = LinearRegression().fit(X, y)
        y_pred = model.predict(X)
        mse = mean_squared_error(y, y_pred)
        r2 = r2_score(y, y_pred)
        if mse < best_mse:
            best_mse = mse
            best_r2 = r2
            best_dim = dim

    cluster_ids.append(i)
    mse_list.append(best_mse)
    r2_list.append(best_r2)
    best_dims.append(['x', 'y', 'z'][best_dim])

# Plotting MSE
plt.figure(figsize=(10, 4))
plt.bar(cluster_ids, mse_list, color='skyblue')
plt.xlabel("Cluster ID")
plt.ylabel("MSE")
plt.title("Linear Regression MSE per Cluster")
plt.grid(True)
plt.show()

# Plotting R²
plt.figure(figsize=(10, 4))
plt.bar(cluster_ids, r2_list, color='lightgreen')
plt.xlabel("Cluster ID")
plt.ylabel("R² Score")
plt.title("Linear Regression R² per Cluster")
plt.grid(True)
plt.show()

"""# 2. Linear regression Questions (In less than 100 words each):
- How shall we estimate the performance of the linear regression?
- What could we do if the the fitting of the plane was not good enough?
- How can we tell if the model is overfitting or underfitting our data?

1. How shall we estimate the performance of the linear regression?

* The performance of linear regression can be evaluated using Mean Squared Error (MSE), R² score, and cross-validation. MSE measures the average squared difference between predicted and actual values, with lower values indicating better fit. R² (coefficient of determination) quantifies how well the model explains variance in the data. Cross-validation (e.g., k-fold) ensures robustness by testing the model on different subsets.

2. What could we do if the fitting of the plane was not good enough?

* If the plane does not fit well, we can add more relevant features, transform variables (e.g., polynomial regression for non-linearity), remove outliers, normalize data, or use regularization (e.g., Lasso, Ridge) to prevent overfitting.

3. How can we tell if the model is overfitting or underfitting our data?

* Overfitting occurs when the model performs well on training data but poorly on test data. A high training R² but low test R² indicates overfitting. Underfitting happens when both training and test errors are high, meaning the model is too simple. Cross-validation and learning curves help diagnose overfitting vs. underfitting.

# 3. Gaussian Process Regression

Similarly, Gaussian process models can be used in higher dimensions too. Model the ground with a GP, where the height is the estimated quantity.

> Perform Gaussian process regression on the height data.

> Note: we are no longer working with zero-mean data, and the kernel hyperparameters should be  chosen carefully.

> With the 2-dimensional input, the kernel function needs to change: it should take 2D vectors and return scalars.

> The training data should be considered noisy, with a standard deviation of 1cm (point cloud units are in meters).

> The model can be used at arbitrary locations, use `bounding_grid` to query the model on a regular grid instead of at the original (training) locations.
"""

df_ground = df_test[df_test['pred'] == 'terrain']
locations = df_ground[['x','y']].to_numpy()
heights = df_ground['z'].to_numpy()
df_ground

# See the mean and variance of the modelled property
mu = np.mean(locations) # TODO
sigma= np.cov(locations, ddof=0) * np.eye(len(locations))  # TODO
# mu, sigma

lengthscale = 3 # meter  # TODO
sigma_f = 0.6792 # meter

def kernel(x1, x2, sigma=sigma_f, lengthscale=lengthscale):
    sqdist = np.sum(x1**2, 1).reshape(-1, 1) + np.sum(x2**2, 1) - 2 * np.dot(x1, x2.T)
    return  sigma**2 * np.exp(-0.5 / lengthscale**2 * sqdist) # TODO

## inputs
xd = locations
yd = df_ground['z'].to_numpy().reshape(-1, 1)
nd = len(locations)
xq = bounding_grid(locations, n=1000)

std_n = 0.1 #TODO
Snn = std_n**2 * np.eye(len(xd))#TODO

## evaluating the kernel
#TODO
Kdd = kernel(xd, xd) + std_n**2 * np.eye(len(xd)) # data-data covariance
Kqd = kernel(xq, xd)  # query-data covariance
Kdq = kernel(xd, xq)  # data-query covariance
Kqq = kernel(xq, xq)  # query-query covariance

## the GP equations
#TODO

mean_q = Kqd @ np.linalg.solve(Kdd + Snn, yd)# TODO
cov_qq = Kqq - Kqd @ np.linalg.solve(Kdd + Snn, Kdq)            # TODO
var_q  = np.diag(cov_qq)# TODO
std_q  = np.sqrt(var_q)# TODO
print(mean_q.shape, cov_qq.shape, var_q.shape, std_q.shape)

"""Plot the estimated height of the ground alongside with the uncertainty:"""

# TODO
# Ground Truth
fig = plot_cloud(
    df_ground,
    x='x', y='y', z='z', color='z',
    color_continuous_scale='Viridis'
)
fig.update_layout(
    title="Ground Truth",
    scene=dict(zaxis_title="Height"),
    coloraxis_colorbar=dict(title="Height (m)")
)

# Gaussian Process Estimation
df_gp = pd.DataFrame({'x': xq[:, 0], 'y': xq[:, 1], 'z': mean_q.flatten()})
fig_gp = plot_cloud(
    df_gp,
    x='x', y='y', z='z', color='z',
    color_continuous_scale='Viridis'
)
fig_gp.update_layout(
    title="Gaussian Process Estimation",
    scene=dict(zaxis_title="Estimated Height"),
    coloraxis_colorbar=dict(title="GP Mean (m)")
)

# Uncertainty
df_uncertainty = pd.DataFrame({
    'x': xq[:, 0], 'y': xq[:, 1],
    'z': mean_q.flatten(),
    'uncertainty': std_q.flatten()
})
fig_uncertainty = plot_cloud(
    df_uncertainty,
    x='x', y='y', z='z', color='uncertainty',
    color_continuous_scale='RdBu'
)
fig_uncertainty.update_layout(
    title="Uncertainty (Standard Deviation)",
    scene=dict(zaxis_title="Estimated Height"),
    coloraxis_colorbar=dict(title="STD (m)")
)

fig.show()
fig_gp.show()
fig_uncertainty.show()


# then plot the estimation with the uncertainty

"""### Combined Visualization: Ground Truth, GP Prediction, and Uncertainty

The following interactive 3D plot combines three key layers:

- **Ground Truth**: Raw terrain measurements labeled as 'terrain' (in gray).
- **GP Prediction**: Mean height estimates obtained from Gaussian Process regression (in Viridis colormap).
- **Uncertainty**: Standard deviation (STD) of the GP predictions, visualized as a heatmap using the RdBu colormap.

A toggle button allows switching between each layer or displaying them together for comparison. This visualisation effectively demonstrates the model’s predictive performance and highlights regions of higher uncertainty.

"""

# # Ground Truth
# layer_ground = go.Scatter3d(
#     x=locations[:, 0],
#     y=locations[:, 1],
#     z=heights,
#     mode='markers',
#     marker=dict(
#         size=2,
#         color=heights,
#         colorscale='Gray',
#         opacity=0.4,
#         colorbar=dict(title='Height')
#     ),
#     name='Ground Truth'
# )

# # GP Estimation
# layer_gp = go.Scatter3d(
#     x=xq[:, 0],
#     y=xq[:, 1],
#     z=mean_q.flatten(),
#     mode='markers',
#     marker=dict(
#         size=2,
#         color=mean_q.flatten(),
#         colorscale='Viridis',
#         colorbar=dict(title='GP Mean (m)'),
#         showscale=True
#     ),
#     name='GP Prediction'
# )

# # Uncertainty (Standard Deviation)
# layer_std = go.Scatter3d(
#     x=xq[:, 0],
#     y=xq[:, 1],
#     z=mean_q.flatten(),
#     mode='markers',
#     marker=dict(
#         size=2,
#         color=std_q,
#         colorscale='RdBu',
#         colorbar=dict(title='STD (m)'),
#         showscale=True
#     ),
#     name='Uncertainty'
# )

# # Combine the three layers into one figure
# fig_combined = go.Figure(data=[layer_ground, layer_gp, layer_std])
# fig_combined.update_layout(
#     title="Ground Truth + GP Prediction + Uncertainty (3-in-1)",
#     scene=dict(
#         xaxis_title='X',
#         yaxis_title='Y',
#         zaxis_title='Height (m)',
#         aspectmode='data'
#     ),
#     margin=dict(b=0, t=40),  # Reserve space for the title
# )

# # Add buttons to toggle layer visibility
# fig_combined.update_layout(
#     updatemenus=[dict(
#         type="buttons",
#         buttons=[
#             dict(label="Show All", method="update", args=[{"visible": [True, True, True]}]),
#             dict(label="Only GP", method="update", args=[{"visible": [False, True, False]}]),
#             dict(label="Only Uncertainty", method="update", args=[{"visible": [False, False, True]}]),
#             dict(label="Only Ground", method="update", args=[{"visible": [True, False, False]}]),
#         ],
#         direction="down",
#         showactive=True,
#         x=0.1,
#         y=1.1
#     )]
# )

# # Apply the custom template from plot_cloud
# fig_combined.update_layout(**plot_cloud.template['layout'])

# # Display the figure
# fig_combined.show()

"""### Evaluation of Gaussian Process Regression (GPR)

To quantitatively assess the accuracy of the GPR model, we compute the **Mean Squared Error (MSE)** and **Root Mean Squared Error (RMSE)** between the predicted terrain heights and the ground truth.

Additionally, we visualise:
- **Histogram of residuals**: showing the distribution of prediction errors.
- **Uncertainty vs. absolute error**: verifying whether the model's predicted standard deviation (uncertainty) correlates with actual prediction error.

> Note: A custom hyperparameter optimization function `fit_gp_with_mle()` was implemented to improve the GP model by maximizing the log marginal likelihood. Although it is commented out in this version, it can be used to further enhance accuracy and uncertainty estimates.

Hyperparameter Optimization
"""

# from scipy.optimize import minimize

# def fit_gp_with_mle(xd, yd, xq, std_n=0.1, z_range=None, verbose=True):
#     """
#     Fit a Gaussian Process using Maximum Likelihood Estimation (MLE) to optimize kernel hyperparameters.

#     Parameters:
#         xd (n×2): training inputs (e.g., x, y)
#         yd (n×1): training targets (e.g., z)
#         xq (m×2): query points
#         std_n (float): assumed noise standard deviation (in meters)
#         z_range (tuple or None): optionally adjust sigma_f bounds based on terrain variation
#         verbose (bool): whether to print optimized parameters

#     Returns:
#         mean_q (m×1): predicted mean at query points
#         std_q (m×1): predicted standard deviation at query points
#         best_lengthscale (float): optimized kernel lengthscale
#         best_sigma_f (float): optimized signal amplitude
#     """

#     # Dynamically determine bounds based on target z-range
#     if z_range is None:
#         z_min, z_max = yd.min(), yd.max()
#     else:
#         z_min, z_max = z_range
#     z_span = z_max - z_min
#     sigma_f_bounds = (0.1, max(0.5, min(z_span * 2, 10.0)))
#     lengthscale_bounds = (0.1, 3.0)

#     # Squared exponential (RBF) kernel
#     def kernel(x1, x2, lengthscale, sigma_f):
#         sqdist = np.sum(x1**2, 1).reshape(-1, 1) + np.sum(x2**2, 1) - 2 * np.dot(x1, x2.T)
#         return sigma_f**2 * np.exp(-0.5 / lengthscale**2 * sqdist)

#     # Negative log marginal likelihood (NLL)
#     def negative_log_marginal_likelihood(params):
#         lengthscale, sigma_f = params
#         try:
#             K = kernel(xd, xd, lengthscale, sigma_f) + std_n**2 * np.eye(len(xd))
#             L = np.linalg.cholesky(K + 1e-6 * np.eye(len(xd)))  # stabilize numerics
#             alpha = np.linalg.solve(L.T, np.linalg.solve(L, yd))
#             logdet = 2.0 * np.sum(np.log(np.diag(L)))
#             nll = 0.5 * yd.T @ alpha + 0.5 * logdet + 0.5 * len(xd) * np.log(2 * np.pi)
#             return nll.flatten()[0]
#         except np.linalg.LinAlgError:
#             return np.inf

#     # Try multiple initial values to avoid local optima
#     init_guesses = [[0.5, 1.0], [1.0, 1.0], [2.0, 1.0], [1.0, 0.5]]
#     best_res = None
#     for guess in init_guesses:
#         res = minimize(
#             negative_log_marginal_likelihood,
#             x0=guess,
#             bounds=[lengthscale_bounds, sigma_f_bounds],
#             method='L-BFGS-B'
#         )
#         if best_res is None or res.fun < best_res.fun:
#             best_res = res

#     best_lengthscale, best_sigma_f = best_res.x

#     # GP prediction using optimized hyperparameters
#     Kdd = kernel(xd, xd, best_lengthscale, best_sigma_f) + std_n**2 * np.eye(len(xd))
#     Kqd = kernel(xq, xd, best_lengthscale, best_sigma_f)
#     Kdq = kernel(xd, xq, best_lengthscale, best_sigma_f)
#     Kqq = kernel(xq, xq, best_lengthscale, best_sigma_f)

#     mean_q = Kqd @ np.linalg.solve(Kdd, yd)
#     cov_qq = Kqq - Kqd @ np.linalg.solve(Kdd, Kdq)
#     std_q = np.sqrt(np.clip(np.diag(cov_qq), 0, np.inf))

#     if verbose:
#         print(f"Best lengthscale: {best_lengthscale:.4f}")
#         print(f"Best sigma_f: {best_sigma_f:.4f}")

#     return mean_q, std_q, best_lengthscale, best_sigma_f

# mean_q, std_q, lengthscale_opt, sigma_f_opt = fit_gp_with_mle(xd, yd, xq, std_n=0.1)

"""Evaluation"""

from sklearn.metrics import mean_squared_error

# Numerical Evaluation
y_true = df_ground['z'].to_numpy()
y_pred = mean_q[:len(y_true)].flatten()
residual = y_pred - y_true
abs_error = np.abs(residual)
pred_std = std_q[:len(y_true)]

# MSE & RMSE
gp_mse = mean_squared_error(y_true, y_pred)
gp_rmse = np.sqrt(gp_mse)
print(f"Gaussian Process Regression MSE: {gp_mse:.4f}")
print(f"RMSE: {gp_rmse:.4f}")
print(f"Mean predicted standard deviation: {np.mean(pred_std):.4f}")

# Figure 1: Histogram of Residuals
plt.figure(figsize=(8, 5))
plt.hist(residual, bins=30, edgecolor='k', alpha=0.7)
plt.title("Histogram of Residuals (GP Prediction)")
plt.xlabel("Prediction Error (m)")
plt.ylabel("Count")
plt.grid(True)
plt.show()

# Figure 2: Uncertainty vs Actual Error
plt.figure(figsize=(8, 5))
plt.scatter(pred_std, abs_error, alpha=0.5, s=10)
plt.xlabel("Predicted Standard Deviation (Uncertainty)")
plt.ylabel("Absolute Prediction Error")
plt.title("Uncertainty vs Absolute Error (GPR)")
plt.grid(True)
plt.show()

"""# 4. GP Questions (In less than 100 words each):
- What is happening in the area where no points are rpovided to the GP (discuss the mean values and the uncertainty)?
- Which kernel we are using and why this is important?

1. What is happening in the area where no points are provided to the GP (discuss the mean values and the uncertainty)?
* In regions where no training points exist, Gaussian Process (GP) relies on the prior mean and kernel function to estimate values. If a zero-mean prior is used, the predictions trend toward zero. The uncertainty (variance) increases as the distance from training points grows because the GP is less confident in predictions. The kernel function determines how far correlations extend, affecting uncertainty growth in unobserved areas.

2. Which kernel are we using and why is this important?
* We are using the Radial Basis Function (RBF) kernel, which assumes smooth variations in the data. The kernel defines how data points influence each other and controls model smoothness. A well-chosen kernel improves interpolation accuracy and prevents overfitting or underfitting.
"""